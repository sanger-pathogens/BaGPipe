// Pipeline input parameters
params {
    manifest = ""
    genus = ""
    phenotypes = ""
    chosen_phenotype = ""
    reference = ""
    outdir = "./output"
    help = false
    
    // Running Options
    genotype_method = ""
    annotation_method = "bakta"
    mygff  = ""
    mytree = ""
    mvcf = ""
    fe = false

    // Max resource options
    // Defaults only, expecting to be overwritten in profiles
    max_memory = '4.GB'
    max_cpus = 2
    max_time = '10000.h'
    max_retries = 3

    // Alternative options for some processes
    // PanarooAnalysis
    panaroo_clean_mode = "strict"
    panaroo_alignment = "core"
    panaroo_aligner = "mafft"
    panaroo_core_threshold = 0.95

    // Annotation
    bakta_args = ""
    bakta_db = ""

    // PhylogeneticAnalysis
    iqtree_model = "GTR"
    iqtree_bootstrap_trees = 1000
    iqtree_seed = 1234
    iqtree_args = ""  // Additional IQtree options can be supplied here. Incompatible with the following, which are reserved for use by this pipeline: -pre, -fconst, -s, -nt, -ntmax, -mem, -bb, -m, -seed

    // Pyseer
    pyseer_min_af = 0.01
    pyseer_max_af = 0.99

    // nf-core config (for profile inheritance)
    nf_core_custom_config_version = 'master'
    nf_core_custom_config_base = "https://raw.githubusercontent.com/nf-core/configs"
    nf_core_custom_config = ""
}

// Load nf-core custom profiles from different Institutions
load_nfcore_profile_config()

/**
* Function to ensure that resource requirements don't go beyond
* a maximum limit
*/
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}

def escalate_linear(initial, task, multiplier=1) {
    assert multiplier > 0
    return (initial * multiplier * task.attempt)
}

def escalate_exp(initial, task, multiplier=1) {
    assert multiplier > 0
    return (initial * (multiplier ** (task.attempt - 1)))
}

def escalate_queue_time(queue, task) {
    def queue_index = [
        "normal": 0,
        "long": 1,
        "week": 2,
        "basement": 3,
    ]
    def times = [12, 48, 168, 720]
    def index = queue_index[queue] + (task.attempt - 1)
    if (index < 4) {
        return "${times[index]}.h"
    }
    return "${times[3]}.h"
}

def retry_strategy(task, max_retries) {
    def MISC_EXIT_CODES = [
        "SIGKILL": 137,
        "SIGTERM": 143,
        "SIGABRT": 134,
        "SIGSEGV": 139
    ].values()

    def SCALING_EXIT_CODES = [
        "SIGINT": 130,  // LSF Out of memory Error or bkill
        "SIGUSR2": 140, // LSF Runlimit exceeded Error
    ].values()

    if (task.attempt > max_retries) {
        return 'ignore'
    }

    switch(task.exitStatus) {
        case {it in MISC_EXIT_CODES}:
            // Ignore due to non-scalable error code
            return 'ignore'

        case {it in SCALING_EXIT_CODES}:
            // Retry with more memory and longer time limit
            return 'retry'

        default:
            // Ignore any other error codes
            return 'ignore'
    }
}

def load_nfcore_profile_config() {
    params.custom_config_base = "${params.nf_core_custom_config_base}/${params.nf_core_custom_config_version}"
    def nf_core_config_url = params.nf_core_custom_config ? params.nf_core_custom_config : "${params.custom_config_base}/nfcore_custom.config"
    try {
        includeConfig "${nf_core_config_url}"
    } catch (Exception e) {
        System.err.println("ERROR: Could not load nf-core/config profiles config: ${nf_core_config_url}")
        System.err.println("Encountered the following exception:")
        throw e
    }
}

// Default executor (possible to override in profiles)
executor {
    name = 'lsf'
    queueSize = 100
    perJobMemLimit = true
    poolSize = 8
    submitRateLimit = '5sec'
    killBatchSize = 50
    pollInterval = '5s'
}

process {

    // Defaults
    cpus   = { check_max( escalate_linear( 1, task ), 'cpus' ) }
    memory = { check_max( escalate_linear( 1.GB, task ), 'memory' ) }
    time   = { check_max( escalate_linear( 1.h, task ), 'time' ) }

    maxErrors = -1
    maxRetries = params.max_retries
    errorStrategy = { retry_strategy(task, params.max_retries) }

    withName:ProkkaAnnotate{
        errorStrategy = 'retry'
        maxRetries = 5
        cpus = { check_max( 4, 'cpus' ) }
        memory = { check_max( escalate_exp( 4.GB, task, 2 ), 'memory' ) }
        time = { check_max( escalate_exp( 12.h, task, 2 ), 'time' ) }
    }

    withName:BaktaAnnotate{
        errorStrategy = 'retry'
        maxRetries = 5
        cpus = { check_max( 4, 'cpus' ) }
        memory = { check_max( escalate_exp( 16.GB, task, 2 ), 'memory' ) }
        time = { check_max( escalate_exp( 12.h, task, 2 ), 'time' ) }
    }

    withName:PanarooAnalysis{
        cpus = { check_max( 64, 'cpus' ) }
        memory = { check_max( escalate_exp( 32.GB, task, 2 ), 'memory' ) }
        time = { check_max( escalate_exp( 24.h, task, 2 ), 'time' ) }
    }

    withName:ExtractSNPs{
        cpus = { check_max( 1, 'cpus' ) }
        memory = { check_max( escalate_exp( 8.GB, task, 2 ), 'memory' ) }
        time = { check_max( escalate_exp( 1.h, task, 2 ), 'time' ) }
    }

    withName:ConstantSitesFreq{
        cpus = { check_max( 1, 'cpus' ) }
        memory = { check_max( escalate_exp( 8.GB, task, 2 ), 'memory' ) }
        time = { check_max( escalate_exp( 1.h, task, 2 ), 'time' ) }
    }

    withName:IQTree{
        cpus = { check_max( 8, 'cpus' ) }
        memory = { check_max( escalate_exp( 8.GB, task, 2 ), 'memory' ) }
        time = { check_max( escalate_exp( 12.h, task, 2 ), 'time' ) }
    }

    withName:UnitigCaller{
        cpus = { check_max( 16, 'cpus' ) }
        memory = { check_max( escalate_exp( 4.GB, task, 2 ), 'memory' ) }
        time = { check_max( escalate_exp( 12.h, task, 2 ), 'time' ) }
    }

    withName:PyseerUnitig{
        cpus = { check_max( 2, 'cpus' ) }
        memory = { check_max( escalate_exp( 2.GB, task, 2 ), 'memory' ) }
        time = { check_max( escalate_exp( 12.h, task, 2 ), 'time' ) }
    }

    withName:PyseerPreAbs{
        cpus = { check_max( 2, 'cpus' ) }
        memory = { check_max( escalate_exp( 2.GB, task, 2 ), 'memory' ) }
        time = { check_max( escalate_exp( 12.h, task, 2 ), 'time' ) }
    }

    withName:PyseerVariants{
        cpus = { check_max( 2, 'cpus' ) }
        memory = { check_max( escalate_exp( 2.GB, task, 2 ), 'memory' ) }
        time = { check_max( escalate_exp( 12.h, task, 2 ), 'time' ) }
    }

    withName:PyseerGenotypeMatrix{
        cpus = { check_max( 2, 'cpus' ) }
        memory = { check_max( escalate_exp( 4.GB, task, 2 ), 'memory' ) }
        time = { check_max( escalate_exp( 12.h, task, 2 ), 'time' ) }
    }

    withName:AnnotateKmers{
        cpus = { check_max( 2, 'cpus' ) }
        memory = { check_max( escalate_exp( 2.GB, task, 2 ), 'memory' ) }
        time = { check_max( escalate_exp( 12.h, task, 2 ), 'time' ) }
    }

    withName:WriteReferenceText{
	    cpus = { check_max( 2, 'cpus' ) }
	    memory = { check_max( escalate_exp( 2.GB, task, 2 ), 'memory' ) }
        time = { check_max( escalate_exp( 12.h, task, 2 ), 'time' ) }
    }
}

profiles {
    singularity {
        singularity.enabled    = true
        singularity.autoMounts = true
        docker.enabled         = false
    }

    docker {
        docker.enabled         = true
        singularity.enabled    = false
        conda.enabled         = false
    }
}
